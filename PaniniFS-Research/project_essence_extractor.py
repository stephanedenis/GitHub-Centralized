#!/usr/bin/env python3
"""
Project Essence Extractor - Capture Vision Avant Archivage

Extrait l'essence, motivations et valeur potentielle de chaque projet
avant d√©cision d'archivage. Cr√©e backlog structur√© pour futures r√©activations.

Principe: "Rien ne se perd, tout se transforme"
Pattern: *_extractor.py (auto-approved via whitelist)

Auteur: Autonomous System
Timestamp: 2025-10-01T16:00:00Z
"""

import os
import json
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple


class ProjectEssenceExtractor:
    """Extracteur essence projets avant archivage."""
    
    def __init__(self, workspace_root: str):
        """Initialise l'extracteur."""
        self.workspace_root = Path(workspace_root)
        
        # Projets candidats archivage (depuis mission_alignment_analyzer)
        self.candidates = [10, 8, 7, 6, 3]
        
        # D√©finitions projets
        self.github_projects = self._load_github_projects()
        
        # Scan docs pour mentions
        self.project_mentions = self._scan_all_mentions()
        
        # R√©sultats extraction
        self.essence_report = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'projects_analyzed': [],
            'backlog_items': [],
            'preservation_recommendations': []
        }
    
    def _load_github_projects(self) -> Dict[int, Dict[str, Any]]:
        """Charge d√©finitions projets."""
        return {
            10: {
                "name": "[INTERFACES] dhatu-api-gateway",
                "category": "INTERFACES",
                "status": "PLANIFI√â",
                "priority": "MOYENNE"
            },
            8: {
                "name": "[TOOLS] dhatu-evolution-simulator",
                "category": "TOOLS",
                "status": "PLANIFI√â",
                "priority": "BASSE"
            },
            7: {
                "name": "[TOOLS] dhatu-space-visualizer",
                "category": "TOOLS",
                "status": "PLANIFI√â",
                "priority": "BASSE"
            },
            6: {
                "name": "[TOOLS] dhatu-creative-generator",
                "category": "TOOLS",
                "status": "PLANIFI√â",
                "priority": "BASSE"
            },
            3: {
                "name": "[CORE] dhatu-web-framework",
                "category": "CORE",
                "status": "PLANIFI√â",
                "priority": "MOYENNE"
            }
        }
    
    def _scan_all_mentions(self) -> Dict[int, List[Dict[str, Any]]]:
        """Scan tous documents pour mentions projets."""
        mentions = {proj_id: [] for proj_id in self.candidates}
        
        # Documents √† scanner
        doc_patterns = [
            '*.md',
            '*.json',
            '*.py'
        ]
        
        for pattern in doc_patterns:
            for doc_path in self.workspace_root.glob(pattern):
                if doc_path.is_file() and doc_path.stat().st_size < 1_000_000:
                    try:
                        with open(doc_path, 'r', encoding='utf-8') as f:
                            content = f.read()
                        
                        # Chercher mentions projets
                        for proj_id in self.candidates:
                            proj_name = self.github_projects[proj_id]['name']
                            
                            # Patterns recherche
                            patterns = [
                                rf'(?i)project\s*#?{proj_id}\b',
                                rf'(?i){re.escape(proj_name)}',
                                rf'(?i)dhatu[-_]' + proj_name.split('-', 2)[-1] if 'dhatu' in proj_name else ''
                            ]
                            
                            for pattern in patterns:
                                if pattern and re.search(pattern, content):
                                    # Extraire contexte (3 lignes avant/apr√®s)
                                    lines = content.split('\n')
                                    for i, line in enumerate(lines):
                                        if re.search(pattern, line):
                                            context_start = max(0, i-3)
                                            context_end = min(len(lines), i+4)
                                            context = '\n'.join(lines[context_start:context_end])
                                            
                                            mentions[proj_id].append({
                                                'file': str(doc_path.name),
                                                'line_number': i+1,
                                                'context': context[:300],
                                                'match_type': 'project_id' if f'#{proj_id}' in pattern else 'name'
                                            })
                                            break  # Une mention par fichier suffit
                    except Exception as e:
                        continue
        
        return mentions
    
    def extract_essence(self, project_id: int) -> Dict[str, Any]:
        """Extrait essence d'un projet."""
        proj_info = self.github_projects[project_id]
        proj_name = proj_info['name']
        
        print(f"\n{'='*70}")
        print(f"üîç PROJECT #{project_id}: {proj_name}")
        print(f"{'='*70}")
        
        essence = {
            'project_id': project_id,
            'name': proj_name,
            'category': proj_info['category'],
            'original_status': proj_info['status'],
            'original_priority': proj_info['priority']
        }
        
        # 1. Inf√©rence motivation depuis nom
        motivation = self._infer_motivation_from_name(proj_name)
        essence['inferred_motivation'] = motivation
        
        # 2. Mentions dans docs
        mentions = self.project_mentions.get(project_id, [])
        essence['mentions_count'] = len(mentions)
        essence['mentioned_in_files'] = list(set(m['file'] for m in mentions))
        
        if mentions:
            essence['sample_contexts'] = [m['context'] for m in mentions[:3]]
        
        # 3. Valeur potentielle
        potential_value = self._assess_potential_value(project_id, proj_info, mentions)
        essence['potential_value'] = potential_value
        
        # 4. Bonnes id√©es √† pr√©server
        good_ideas = self._extract_good_ideas(proj_name, mentions)
        essence['good_ideas'] = good_ideas
        
        # 5. D√©pendances potentielles
        dependencies = self._identify_dependencies(project_id, proj_info)
        essence['dependencies'] = dependencies
        
        # 6. Recommandation archivage
        recommendation = self._generate_archival_recommendation(
            project_id, proj_info, potential_value, mentions
        )
        essence['archival_recommendation'] = recommendation
        
        # 7. Backlog items
        backlog = self._create_backlog_items(project_id, proj_info, good_ideas)
        essence['backlog_items'] = backlog
        
        # Affichage r√©sum√©
        self._print_essence_summary(essence)
        
        return essence
    
    def _infer_motivation_from_name(self, proj_name: str) -> str:
        """Inf√®re motivation depuis nom projet."""
        name_lower = proj_name.lower()
        
        motivations = {
            'api-gateway': "Centraliser acc√®s APIs dhƒÅtu - Point d'entr√©e unifi√© √©cosyst√®me",
            'evolution-simulator': "Simuler √©volution temporelle dhƒÅtu - Visualiser transformations linguistiques",
            'space-visualizer': "Visualiser espace s√©mantique dhƒÅtu - Repr√©sentation g√©om√©trique multidimensionnelle",
            'creative-generator': "G√©n√©rer variations cr√©atives dhƒÅtu - Exploration espace linguistique",
            'web-framework': "Framework web complet dhƒÅtu - Infrastructure applications linguistiques"
        }
        
        for keyword, motivation in motivations.items():
            if keyword in name_lower:
                return motivation
        
        return "Motivation non document√©e - Inf√©rence impossible"
    
    def _assess_potential_value(
        self,
        project_id: int,
        proj_info: Dict[str, Any],
        mentions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """√âvalue valeur potentielle projet."""
        value = {
            'strategic_alignment': 0.0,  # 0-10
            'innovation_potential': 0.0,  # 0-10
            'ecosystem_impact': 0.0,      # 0-10
            'effort_to_activate': 0.0,    # 0-10 (moins = mieux)
            'total_score': 0.0            # 0-40
        }
        
        # Strategic alignment (bas√© cat√©gorie)
        category_scores = {
            'CORE': 9,
            'RESEARCH': 8,
            'INTERFACES': 7,
            'TOOLS': 5,
            'ROADMAP': 6
        }
        value['strategic_alignment'] = category_scores.get(proj_info['category'], 5)
        
        # Innovation potential (bas√© nom)
        name = proj_info['name'].lower()
        if 'simulator' in name or 'generator' in name:
            value['innovation_potential'] = 8  # Haute innovation
        elif 'visualizer' in name or 'gateway' in name:
            value['innovation_potential'] = 6  # Innovation moyenne
        elif 'framework' in name:
            value['innovation_potential'] = 7  # Innovation structurelle
        else:
            value['innovation_potential'] = 5
        
        # Ecosystem impact (bas√© mentions)
        if len(mentions) >= 5:
            value['ecosystem_impact'] = 8
        elif len(mentions) >= 2:
            value['ecosystem_impact'] = 6
        elif len(mentions) >= 1:
            value['ecosystem_impact'] = 4
        else:
            value['ecosystem_impact'] = 2
        
        # Effort to activate (invers√©: moins = mieux)
        if proj_info['status'] == 'ACTIF':
            value['effort_to_activate'] = 3  # D√©j√† actif
        elif proj_info['category'] in ['CORE', 'RESEARCH']:
            value['effort_to_activate'] = 7  # Complexe
        else:
            value['effort_to_activate'] = 5  # Moyen
        
        # Total
        value['total_score'] = (
            value['strategic_alignment'] +
            value['innovation_potential'] +
            value['ecosystem_impact'] +
            (10 - value['effort_to_activate'])  # Inverser effort
        )
        
        return value
    
    def _extract_good_ideas(
        self,
        proj_name: str,
        mentions: List[Dict[str, Any]]
    ) -> List[str]:
        """Extrait bonnes id√©es du projet."""
        ideas = []
        
        # Id√©es depuis nom
        name_ideas = {
            'api-gateway': [
                "Point d'entr√©e unifi√© pour tous services dhƒÅtu",
                "Authentification centralis√©e",
                "Rate limiting et monitoring global",
                "API versioning et backward compatibility"
            ],
            'evolution-simulator': [
                "Visualiser transformations dhƒÅtu temporelles",
                "Simuler d√©rivations linguistiques (dhƒÅtu ‚Üí mots)",
                "Pr√©dire √©volutions futures patterns",
                "Benchmarks vitesse/pr√©cision transformations"
            ],
            'space-visualizer': [
                "Repr√©sentation 3D espace s√©mantique dhƒÅtu",
                "Clustering visuel patterns similaires",
                "Navigation interactive g√©om√©trie linguistique",
                "Export visualisations haute r√©solution"
            ],
            'creative-generator': [
                "G√©n√©rer variations linguistiques cr√©atives",
                "Exploration guid√©e espace compositional",
                "Suggestions intelligence artificielle",
                "Mode d√©couverte serendipit√©"
            ],
            'web-framework': [
                "Components r√©utilisables applications dhƒÅtu",
                "State management linguistique",
                "Real-time synchronization corpus",
                "Responsive design multi-devices"
            ]
        }
        
        for keyword, keyword_ideas in name_ideas.items():
            if keyword in proj_name.lower():
                ideas.extend(keyword_ideas)
        
        # Id√©es depuis contextes mentions
        for mention in mentions[:5]:
            context = mention.get('context', '').lower()
            
            # Extraction keywords actions
            action_keywords = [
                'visualiser', 'simuler', 'g√©n√©rer', 'centraliser',
                'transformer', 'explorer', 'd√©couvrir', 'analyser'
            ]
            
            for keyword in action_keywords:
                if keyword in context:
                    # Extraire phrase contenant keyword
                    sentences = re.split(r'[.!?\n]', context)
                    for sentence in sentences:
                        if keyword in sentence.lower() and len(sentence) > 20:
                            ideas.append(sentence.strip())
                            break
        
        return list(set(ideas))  # D√©duplicate
    
    def _identify_dependencies(
        self,
        project_id: int,
        proj_info: Dict[str, Any]
    ) -> Dict[str, List[int]]:
        """Identifie d√©pendances projet."""
        dependencies = {
            'depends_on': [],     # Ce projet d√©pend de...
            'required_by': []     # Ce projet est requis par...
        }
        
        # R√®gles d√©pendances logiques
        category = proj_info['category']
        
        # INTERFACES d√©pendent CORE
        if category == 'INTERFACES':
            dependencies['depends_on'] = [1, 2, 4]  # Compressor, Corpus, GPU
        
        # TOOLS d√©pendent CORE
        elif category == 'TOOLS':
            dependencies['depends_on'] = [2, 4]  # Corpus, GPU
        
        # Web framework d√©pend de tout CORE
        if project_id == 3:
            dependencies['depends_on'] = [1, 2, 4]
        
        # API Gateway pourrait √™tre requis par Dashboard
        if project_id == 10:
            dependencies['required_by'] = [9]  # Dashboard
        
        return dependencies
    
    def _generate_archival_recommendation(
        self,
        project_id: int,
        proj_info: Dict[str, Any],
        potential_value: Dict[str, Any],
        mentions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """G√©n√®re recommandation archivage."""
        recommendation = {
            'decision': 'UNKNOWN',
            'confidence': 0.0,
            'rationale': [],
            'conditions_reactivation': []
        }
        
        score = potential_value['total_score']
        
        # Crit√®res d√©cision
        if score >= 30:
            recommendation['decision'] = 'PRESERVE'
            recommendation['confidence'] = 0.9
            recommendation['rationale'].append(
                f"Score valeur potentielle √©lev√© ({score:.1f}/40)"
            )
        elif score >= 20:
            recommendation['decision'] = 'ARCHIVE_WITH_BACKLOG'
            recommendation['confidence'] = 0.8
            recommendation['rationale'].append(
                f"Score valeur potentielle moyen ({score:.1f}/40) - Bonnes id√©es √† pr√©server"
            )
        else:
            recommendation['decision'] = 'ARCHIVE'
            recommendation['confidence'] = 0.7
            recommendation['rationale'].append(
                f"Score valeur potentielle faible ({score:.1f}/40)"
            )
        
        # Rationale additionnel
        if len(mentions) == 0:
            recommendation['rationale'].append(
                "Aucune mention dans documentation actuelle"
            )
        
        if proj_info['status'] == 'PLANIFI√â' and proj_info['priority'] == 'BASSE':
            recommendation['rationale'].append(
                "Status PLANIFI√â + Priority BASSE sugg√®re non-prioritaire"
            )
        
        # Conditions r√©activation
        if recommendation['decision'] in ['ARCHIVE', 'ARCHIVE_WITH_BACKLOG']:
            recommendation['conditions_reactivation'] = [
                f"Compl√©tion projets CORE (1, 2, 4) √† ‚â•80%",
                f"Demande explicite use case sp√©cifique",
                f"Capacit√© √©quipe: ‚â•2 devs disponibles",
                f"Budget: ‚â•40h estimation effort"
            ]
            
            # Conditions sp√©cifiques
            if proj_info['category'] == 'INTERFACES':
                recommendation['conditions_reactivation'].append(
                    "CORE APIs stables et document√©es"
                )
            elif proj_info['category'] == 'TOOLS':
                recommendation['conditions_reactivation'].append(
                    "Corpus ‚â•100k valid√© et corpus manager op√©rationnel"
                )
        
        return recommendation
    
    def _create_backlog_items(
        self,
        project_id: int,
        proj_info: Dict[str, Any],
        good_ideas: List[str]
    ) -> List[Dict[str, Any]]:
        """Cr√©e items backlog depuis bonnes id√©es."""
        backlog = []
        
        for i, idea in enumerate(good_ideas[:5], 1):  # Top 5
            item = {
                'id': f'backlog_{project_id}_{i:02d}',
                'title': idea[:100],
                'source_project': project_id,
                'source_project_name': proj_info['name'],
                'category': proj_info['category'],
                'priority': 'FUTURE',
                'estimated_effort': 'TBD',
                'prerequisites': self._infer_prerequisites(idea),
                'tags': self._extract_tags(idea)
            }
            backlog.append(item)
        
        return backlog
    
    def _infer_prerequisites(self, idea: str) -> List[str]:
        """Inf√®re pr√©requis depuis id√©e."""
        prerequisites = []
        
        idea_lower = idea.lower()
        
        if 'api' in idea_lower or 'service' in idea_lower:
            prerequisites.append("CORE APIs stabilis√©es")
        
        if 'corpus' in idea_lower or 'donn√©es' in idea_lower:
            prerequisites.append("Corpus ‚â•100k valid√©")
        
        if 'gpu' in idea_lower or 'training' in idea_lower:
            prerequisites.append("Infrastructure GPU op√©rationnelle")
        
        if 'visualis' in idea_lower or '3d' in idea_lower:
            prerequisites.append("Framework visualisation choisi")
        
        if 'real-time' in idea_lower or 'synchron' in idea_lower:
            prerequisites.append("WebSocket infrastructure")
        
        return prerequisites if prerequisites else ["Aucun pr√©requis identifi√©"]
    
    def _extract_tags(self, idea: str) -> List[str]:
        """Extrait tags depuis id√©e."""
        tags = []
        
        idea_lower = idea.lower()
        
        tag_keywords = {
            'visualization': ['visualis', '3d', 'graph', 'chart'],
            'api': ['api', 'endpoint', 'service', 'gateway'],
            'simulation': ['simuler', 'simulation', 'pr√©dire'],
            'generation': ['g√©n√©rer', 'cr√©er', 'produire'],
            'analytics': ['analyser', 'm√©triques', 'benchmark'],
            'ui': ['interface', 'dashboard', 'responsive'],
            'ml': ['intelligence', 'learning', 'model'],
            'performance': ['optimis', 'performance', 'rapide']
        }
        
        for tag, keywords in tag_keywords.items():
            if any(kw in idea_lower for kw in keywords):
                tags.append(tag)
        
        return tags if tags else ['general']
    
    def _print_essence_summary(self, essence: Dict[str, Any]):
        """Affiche r√©sum√© essence."""
        print(f"\nüìä Motivation Inf√©r√©e:")
        print(f"  {essence['inferred_motivation']}")
        
        print(f"\nüìà Valeur Potentielle:")
        pv = essence['potential_value']
        print(f"  Strategic Alignment: {pv['strategic_alignment']:.1f}/10")
        print(f"  Innovation Potential: {pv['innovation_potential']:.1f}/10")
        print(f"  Ecosystem Impact: {pv['ecosystem_impact']:.1f}/10")
        print(f"  Effort to Activate: {pv['effort_to_activate']:.1f}/10")
        print(f"  SCORE TOTAL: {pv['total_score']:.1f}/40")
        
        print(f"\nüí° Bonnes Id√©es Extraites: {len(essence['good_ideas'])}")
        for i, idea in enumerate(essence['good_ideas'][:3], 1):
            print(f"  {i}. {idea[:80]}...")
        
        print(f"\nüîó Mentions Documentation: {essence['mentions_count']}")
        if essence['mentioned_in_files']:
            print(f"  Fichiers: {', '.join(essence['mentioned_in_files'][:3])}")
        
        print(f"\n‚úÖ Recommandation Archivage:")
        rec = essence['archival_recommendation']
        print(f"  D√©cision: {rec['decision']}")
        print(f"  Confiance: {rec['confidence']*100:.0f}%")
        print(f"  Rationale:")
        for rationale in rec['rationale']:
            print(f"    - {rationale}")
        
        if rec['conditions_reactivation']:
            print(f"\nüîÑ Conditions R√©activation:")
            for condition in rec['conditions_reactivation'][:3]:
                print(f"    - {condition}")
        
        print(f"\nüìã Backlog Items Cr√©√©s: {len(essence['backlog_items'])}")
    
    def analyze_all_candidates(self) -> Dict[str, Any]:
        """Analyse tous candidats archivage."""
        print("\n" + "="*70)
        print("üî¨ EXTRACTION ESSENCE PROJETS - AVANT ARCHIVAGE")
        print("="*70)
        print(f"\n5 projets candidats √† analyser: {self.candidates}")
        
        for project_id in self.candidates:
            essence = self.extract_essence(project_id)
            self.essence_report['projects_analyzed'].append(essence)
            
            # Accumuler backlog items
            self.essence_report['backlog_items'].extend(essence['backlog_items'])
            
            # Recommandations pr√©servation
            if essence['archival_recommendation']['decision'] == 'PRESERVE':
                self.essence_report['preservation_recommendations'].append({
                    'project_id': project_id,
                    'name': essence['name'],
                    'reason': essence['archival_recommendation']['rationale']
                })
        
        # Statistiques finales
        self._generate_final_statistics()
        
        return self.essence_report
    
    def _generate_final_statistics(self):
        """G√©n√®re statistiques finales."""
        print("\n" + "="*70)
        print("üìä STATISTIQUES FINALES EXTRACTION")
        print("="*70)
        
        total = len(self.essence_report['projects_analyzed'])
        
        # Distribution d√©cisions
        decisions = {}
        total_score = 0
        for proj in self.essence_report['projects_analyzed']:
            decision = proj['archival_recommendation']['decision']
            decisions[decision] = decisions.get(decision, 0) + 1
            total_score += proj['potential_value']['total_score']
        
        print(f"\nüìà Distribution D√©cisions:")
        for decision, count in decisions.items():
            print(f"  {decision}: {count} projets")
        
        print(f"\nüí° Bonnes Id√©es Totales: {len(self.essence_report['backlog_items'])}")
        
        print(f"\nüìã Backlog Items par Cat√©gorie:")
        backlog_by_category = {}
        for item in self.essence_report['backlog_items']:
            category = item['category']
            backlog_by_category[category] = backlog_by_category.get(category, 0) + 1
        
        for category, count in sorted(backlog_by_category.items()):
            print(f"  {category}: {count} items")
        
        avg_score = total_score / total if total > 0 else 0
        print(f"\n‚≠ê Score Potentiel Moyen: {avg_score:.1f}/40")
        
        if self.essence_report['preservation_recommendations']:
            print(f"\n‚ö†Ô∏è  Projets √Ä PR√âSERVER (haute valeur):")
            for rec in self.essence_report['preservation_recommendations']:
                print(f"  - Project #{rec['project_id']}: {rec['name']}")
    
    def export_report(self, output_file: Optional[Path] = None) -> Path:
        """Export rapport essence."""
        if output_file is None:
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H-%M-%SZ')
            output_file = (
                self.workspace_root /
                f'project_essence_extraction_{timestamp}.json'
            )
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.essence_report, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ Rapport essence export√©: {output_file.name}")
        return output_file
    
    def export_backlog_markdown(self, output_file: Optional[Path] = None) -> Path:
        """Export backlog en Markdown lisible."""
        if output_file is None:
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H-%M-%SZ')
            output_file = (
                self.workspace_root /
                f'BACKLOG_ARCHIVED_PROJECTS_{timestamp}.md'
            )
        
        lines = [
            "# üìã Backlog Id√©es - Projets Archiv√©s",
            "",
            f"**Date**: {datetime.now(timezone.utc).strftime('%Y-%m-%d')}",
            f"**Source**: Extraction essence 5 projets archiv√©s",
            f"**Total Items**: {len(self.essence_report['backlog_items'])}",
            "",
            "---",
            "",
            "## üéØ Principe",
            "",
            "Ce document pr√©serve les **bonnes id√©es** des projets archiv√©s.",
            "Rien n'est perdu - ces id√©es peuvent √™tre r√©activ√©es quand:",
            "- Les pr√©requis sont remplis",
            "- Un use case concret √©merge",
            "- Les ressources sont disponibles",
            "",
            "---",
            ""
        ]
        
        # Grouper par cat√©gorie
        by_category = {}
        for item in self.essence_report['backlog_items']:
            category = item['category']
            if category not in by_category:
                by_category[category] = []
            by_category[category].append(item)
        
        for category in sorted(by_category.keys()):
            items = by_category[category]
            lines.append(f"## üì¶ {category} ({len(items)} items)")
            lines.append("")
            
            for item in items:
                lines.append(f"### {item['title']}")
                lines.append("")
                lines.append(f"**Source**: Project #{item['source_project']} - {item['source_project_name']}")
                lines.append(f"**Priority**: {item['priority']}")
                lines.append(f"**Effort**: {item['estimated_effort']}")
                lines.append("")
                
                if item['prerequisites']:
                    lines.append("**Pr√©requis**:")
                    for prereq in item['prerequisites']:
                        lines.append(f"- {prereq}")
                    lines.append("")
                
                if item['tags']:
                    lines.append(f"**Tags**: {', '.join(item['tags'])}")
                    lines.append("")
                
                lines.append("---")
                lines.append("")
        
        # Conditions r√©activation globales
        lines.extend([
            "## üîÑ Conditions R√©activation G√©n√©rales",
            "",
            "Pour r√©activer un item backlog, v√©rifier:",
            "",
            "1. ‚úÖ **Pr√©requis techniques** remplis (CORE projects op√©rationnels)",
            "2. ‚úÖ **Use case concret** identifi√© (pas th√©orique)",
            "3. ‚úÖ **Ressources disponibles** (‚â•40h + budget si externe)",
            "4. ‚úÖ **Alignement strat√©gique** avec roadmap actuelle",
            "5. ‚úÖ **Capacit√© √©quipe** (‚â•2 personnes ou agent autonome)",
            "",
            "---",
            "",
            f"*Rapport g√©n√©r√© automatiquement par project_essence_extractor.py*"
        ])
        
        with open(output_file, 'w', encoding='utf-8') as f:
            f.write('\n'.join(lines))
        
        print(f"‚úÖ Backlog Markdown export√©: {output_file.name}")
        return output_file


def main():
    """Point d'entr√©e principal."""
    workspace = "/home/stephane/GitHub/PaniniFS-Research"
    
    extractor = ProjectEssenceExtractor(workspace)
    
    # Extraction compl√®te
    report = extractor.analyze_all_candidates()
    
    # Export JSON d√©taill√©
    json_output = extractor.export_report()
    
    # Export Markdown backlog
    md_output = extractor.export_backlog_markdown()
    
    # R√©sum√© final
    print("\n" + "="*70)
    print("‚úÖ EXTRACTION ESSENCE COMPL√âT√âE")
    print("="*70)
    print(f"Projets analys√©s: {len(report['projects_analyzed'])}")
    print(f"Backlog items: {len(report['backlog_items'])}")
    print(f"Projets √† pr√©server: {len(report['preservation_recommendations'])}")
    print(f"\nüìÅ Rapports g√©n√©r√©s:")
    print(f"  - {json_output.name} (d√©tails)")
    print(f"  - {md_output.name} (backlog)")
    
    if report['preservation_recommendations']:
        print(f"\n‚ö†Ô∏è  ATTENTION: {len(report['preservation_recommendations'])} projets recommand√©s PR√âSERVATION")
        print("  Review manuelle recommand√©e avant archivage")


if __name__ == '__main__':
    main()
