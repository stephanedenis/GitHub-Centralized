#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
VISUALISEUR DHÄ€TU ET THÃ‰ORIES - CONTENU RÃ‰EL
===========================================
Affiche les dÃ©tails concrets des dhÄtu et thÃ©ories en cours,
pas juste les noms de fichiers.
"""

import json
import re
from pathlib import Path


def show_dhatu_details():
    """Afficher les dÃ©tails concrets des dhÄtu trouvÃ©s"""
    
    # Lire le contenu extrait
    try:
        with open('extracted_content.json', 'r') as f:
            content_data = json.load(f)
    except:
        print("âŒ Fichier extracted_content.json non trouvÃ©")
        return
    
    print("ğŸ”¬ DÃ‰TAILS DHÄ€TU EN COURS D'Ã‰TUDE:")
    print("=" * 50)
    
    dhatu_found = False
    
    for filename, data in content_data.items():
        if data['dhatu_mentions']:
            print(f"\nğŸ“„ {filename}")
            for mention in data['dhatu_mentions']:
                print(f"   ğŸ”¸ {mention}")
            dhatu_found = True
    
    if not dhatu_found:
        print("   â„¹ï¸ Pas de mentions dhÄtu spÃ©cifiques dans les fichiers rÃ©cents")
    
    print("\n" + "=" * 50)


def show_theory_details():
    """Afficher les dÃ©tails des thÃ©ories en dÃ©veloppement"""
    
    try:
        with open('extracted_content.json', 'r') as f:
            content_data = json.load(f)
    except:
        return
    
    print("\nğŸ§  THÃ‰ORIES EN DÃ‰VELOPPEMENT:")
    print("=" * 50)
    
    for filename, data in content_data.items():
        if data['docstrings']:
            print(f"\nğŸ“š {filename}")
            
            for i, docstring in enumerate(data['docstrings'][:2]):  # Max 2 par fichier
                print(f"\n   ğŸ“ ThÃ©orie {i+1}:")
                
                # Nettoyer et formatter la docstring
                clean_doc = clean_docstring(docstring)
                if len(clean_doc) > 100:
                    print(f"   {clean_doc}")
                    
                    # Extraire concepts clÃ©s
                    concepts = extract_key_concepts(clean_doc)
                    if concepts:
                        print(f"   ğŸ”‘ Concepts: {', '.join(concepts[:5])}")


def show_class_details():
    """Afficher les dÃ©tails des classes dÃ©finies"""
    
    try:
        with open('extracted_content.json', 'r') as f:
            content_data = json.load(f)
    except:
        return
    
    print("\nğŸ“š CLASSES ET STRUCTURES DÃ‰FINIES:")
    print("=" * 50)
    
    for filename, data in content_data.items():
        if data['class_definitions']:
            print(f"\nğŸ—ï¸ {filename}")
            
            for class_def in data['class_definitions']:
                print(f"   ğŸ“¦ {class_def['name']}")
                if class_def['docstring']:
                    print(f"      â†’ {class_def['docstring']}")


def show_data_structures():
    """Afficher les structures de donnÃ©es trouvÃ©es"""
    
    try:
        with open('extracted_content.json', 'r') as f:
            content_data = json.load(f)
    except:
        return
    
    print("\nğŸ—ƒï¸ STRUCTURES DE DONNÃ‰ES:")
    print("=" * 50)
    
    for filename, data in content_data.items():
        if data['data_structures']:
            print(f"\nğŸ’¾ {filename}")
            
            for struct in data['data_structures'][:3]:  # Max 3 par fichier
                # Nettoyer la structure
                clean_struct = ' '.join(struct.split())
                if len(clean_struct) > 50:
                    print(f"   ğŸ”¹ {clean_struct[:120]}...")


def clean_docstring(docstring):
    """Nettoyer une docstring pour affichage"""
    # Enlever les caractÃ¨res spÃ©ciaux de formatage
    clean = re.sub(r'[=]+', '', docstring)
    clean = re.sub(r'[-]+', '', clean)
    clean = re.sub(r'\n+', ' ', clean)
    clean = re.sub(r'\s+', ' ', clean)
    return clean.strip()


def extract_key_concepts(text):
    """Extraire les concepts clÃ©s d'un texte"""
    # Mots-clÃ©s thÃ©oriques importants
    concepts = []
    
    # Patterns pour concepts
    patterns = [
        r'\b(semantic\w*)\b',
        r'\b(universal\w*)\b',
        r'\b(panini\w*)\b',
        r'\b(information\w*)\b',
        r'\b(theory\w*)\b',
        r'\b(thÃ©orie\w*)\b',
        r'\b(foundation\w*)\b',
        r'\b(fondement\w*)\b',
        r'\b(composition\w*)\b',
        r'\b(fractal\w*)\b',
        r'\b(mapping\w*)\b',
        r'\b(domain\w*)\b',
        r'\b(autonomous\w*)\b',
        r'\b(autonome\w*)\b'
    ]
    
    for pattern in patterns:
        matches = re.findall(pattern, text, re.IGNORECASE)
        concepts.extend(matches)
    
    # Enlever doublons et retourner
    return list(set(concepts))


def show_active_research_focus():
    """Identifier le focus de recherche actuel"""
    
    try:
        with open('extracted_content.json', 'r') as f:
            content_data = json.load(f)
    except:
        return
    
    print("\nğŸ¯ FOCUS DE RECHERCHE ACTUEL:")
    print("=" * 50)
    
    # Compter les mentions par thÃ¨me
    themes = {
        'SÃ©mantique/Universal': 0,
        'SystÃ¨mes Autonomes': 0,
        'ThÃ©orie Information': 0,
        'DhÄtu/Linguistique': 0,
        'Infrastructure/Tech': 0
    }
    
    theme_files = {key: [] for key in themes.keys()}
    
    for filename, data in content_data.items():
        filename_lower = filename.lower()
        all_text = ' '.join(data['docstrings']).lower()
        
        # Classifier par thÃ¨me
        if any(word in all_text for word in ['semantic', 'universal', 'fondement']):
            themes['SÃ©mantique/Universal'] += 1
            theme_files['SÃ©mantique/Universal'].append(filename)
        
        if any(word in all_text for word in ['autonome', 'autonomous', 'apprentissage']):
            themes['SystÃ¨mes Autonomes'] += 1
            theme_files['SystÃ¨mes Autonomes'].append(filename)
        
        if any(word in all_text for word in ['information', 'theory', 'thÃ©orie']):
            themes['ThÃ©orie Information'] += 1
            theme_files['ThÃ©orie Information'].append(filename)
        
        if any(word in all_text for word in ['dhatu', 'dhÄtu', 'linguist']):
            themes['DhÄtu/Linguistique'] += 1
            theme_files['DhÄtu/Linguistique'].append(filename)
        
        if any(word in filename_lower for word in ['github', 'renommeur', 'dashboard']):
            themes['Infrastructure/Tech'] += 1
            theme_files['Infrastructure/Tech'].append(filename)
    
    # Afficher rÃ©sultats
    for theme, count in sorted(themes.items(), key=lambda x: x[1], reverse=True):
        if count > 0:
            print(f"\nğŸ”¸ {theme}: {count} fichier(s)")
            for filename in theme_files[theme][:3]:  # Max 3 exemples
                print(f"   â€¢ {filename}")
    
    # Identifier focus principal
    main_focus = max(themes.items(), key=lambda x: x[1])
    if main_focus[1] > 0:
        print(f"\nğŸ¯ FOCUS PRINCIPAL: {main_focus[0]} ({main_focus[1]} fichiers)")


def main():
    """Affichage principal du contenu"""
    print("ğŸ“– VISUALISEUR CONTENU PANINI - DÃ‰TAILS RÃ‰ELS")
    print("=" * 60)
    
    # VÃ©rifier si le fichier d'extraction existe
    if not Path('extracted_content.json').exists():
        print("\nâš ï¸ Extraction du contenu requise...")
        print("ğŸ“ ExÃ©cutez d'abord: python3 extract_direct_content.py")
        return
    
    # Afficher les diffÃ©rentes sections
    show_active_research_focus()
    show_theory_details()
    show_class_details() 
    show_dhatu_details()
    show_data_structures()
    
    print("\n" + "=" * 60)
    print("âœ… Visualisation contenu terminÃ©e")
    print("ğŸ’¡ Ceci montre le CONTENU rÃ©el, pas juste les noms de fichiers")


if __name__ == "__main__":
    main()