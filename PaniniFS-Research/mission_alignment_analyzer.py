#!/usr/bin/env python3
"""
Mission Alignment Analyzer - Audit Coh√©rence √âcosyst√®me Panini

Analyse l'alignement et la coh√©rence entre:
- GitHub Projects actifs
- PRs en cours
- T√¢ches orchestrateur
- Documentation mission
- Vision/Strat√©gie actuelle

D√©tecte:
- Projets obsol√®tes (vestiges anciennes versions)
- Incoh√©rences objectifs
- Duplications efforts
- Gaps strat√©giques
- Conflits priorit√©s

Pattern: *_analyzer.py (auto-approved via whitelist)

Auteur: Autonomous System
Timestamp: 2025-10-01T15:00:00Z
"""

import os
import json
import re
from datetime import datetime, timezone
from pathlib import Path
from typing import Dict, List, Optional, Any, Set, Tuple


class MissionAlignmentAnalyzer:
    """Analyseur alignement missions √©cosyst√®me Panini."""
    
    def __init__(self, workspace_root: str):
        """Initialise l'analyseur."""
        self.workspace_root = Path(workspace_root)
        
        # Scan documents strat√©giques
        self.strategic_docs = self._scan_strategic_documents()
        
        # Parse GitHub Projects
        self.github_projects = self._load_github_projects()
        
        # Parse orchestrateur tasks
        self.orchestrator_tasks = self._load_orchestrator_tasks()
        
        # Parse PRs actifs
        self.active_prs = self._scan_active_prs()
        
        # R√©sultats analyse
        self.alignment_report = {
            'timestamp': datetime.now(timezone.utc).isoformat(),
            'status': 'ANALYZING',
            'issues': [],
            'recommendations': [],
            'coherence_score': 0.0
        }
    
    def _scan_strategic_documents(self) -> Dict[str, Any]:
        """Scan documents strat√©giques pour extraire vision actuelle."""
        docs = {}
        
        # Documents cl√©s √† analyser
        key_docs = [
            'README_MISSION_PANINI.md',
            'STRATEGIE_RAFFINEE_PLAN_TRAVAIL.md',
            'CLARIFICATIONS_MISSION_CRITIQUE.md',
            'SYNTHESE_CLARIFICATIONS_INTEGREES.md',
            'SESSION_COMPLETE_SYNTHESE_EXECUTIVE.md',
            'PANINI_ECOSYSTEM_ORCHESTRATOR_GUIDE.md'
        ]
        
        for doc_name in key_docs:
            doc_path = self.workspace_root / doc_name
            if doc_path.exists():
                docs[doc_name] = self._parse_strategic_doc(doc_path)
        
        return docs
    
    def _parse_strategic_doc(self, doc_path: Path) -> Dict[str, Any]:
        """Parse un document strat√©gique."""
        with open(doc_path, 'r', encoding='utf-8') as f:
            content = f.read()
        
        # Extraction dates (d√©tection obsolescence)
        dates = re.findall(r'\*\*Date\*\*\s*:\s*(\d{4}-\d{2}-\d{2})', content)
        
        # Extraction objectifs (headers avec verbes action)
        objectives = re.findall(
            r'(?:##|###)\s+(?:‚úÖ|‚ùå|‚ö†Ô∏è|üéØ)?\s*(.+?)(?:\n|$)',
            content
        )
        
        # Extraction m√©triques success
        metrics = re.findall(
            r'(?:M√©triques?|Success|Target|Objectif)\s*[:\-]\s*(.+?)(?:\n|$)',
            content,
            re.IGNORECASE
        )
        
        # Extraction projets mentionn√©s
        projects_mentioned = re.findall(
            r'(?:Project|Projet)\s*#?(\d+)',
            content,
            re.IGNORECASE
        )
        
        # Extraction warnings/deprecated
        warnings = re.findall(
            r'(?:‚ö†Ô∏è|ATTENTION|WARNING|OBSOLETE|DEPRECATED)(.+?)(?:\n|$)',
            content,
            re.IGNORECASE
        )
        
        return {
            'path': str(doc_path),
            'size': len(content),
            'dates': dates,
            'objectives': objectives[:10],  # Top 10
            'metrics': metrics[:5],
            'projects_mentioned': list(set(projects_mentioned)),
            'warnings': warnings,
            'last_modified': datetime.fromtimestamp(
                doc_path.stat().st_mtime
            ).isoformat()
        }
    
    def _load_github_projects(self) -> Dict[int, Dict[str, Any]]:
        """Charge d√©finitions GitHub Projects."""
        # Depuis panini_ecosystem_orchestrator.py
        return {
            15: {
                "name": "Panini - Th√©orie Information Universelle",
                "status": "ACTIF",
                "category": "RESEARCH",
                "priority": "CRITIQUE"
            },
            14: {
                "name": "OntoWave Roadmap",
                "status": "ACTIF",
                "category": "ROADMAP",
                "priority": "STRAT√âGIQUE"
            },
            13: {
                "name": "PaniniFS Research Strategy 2025",
                "status": "ACTIF",
                "category": "RESEARCH",
                "priority": "HAUTE"
            },
            12: {
                "name": "[RESEARCH] dhatu-multimodal-learning",
                "status": "PLANIFI√â",
                "category": "RESEARCH",
                "priority": "MOYENNE"
            },
            11: {
                "name": "[RESEARCH] dhatu-linguistics-engine",
                "status": "ACTIF",
                "category": "RESEARCH",
                "priority": "HAUTE"
            },
            10: {
                "name": "[INTERFACES] dhatu-api-gateway",
                "status": "PLANIFI√â",
                "category": "INTERFACES",
                "priority": "MOYENNE"
            },
            9: {
                "name": "[INTERFACES] dhatu-dashboard",
                "status": "ACTIF",
                "category": "INTERFACES",
                "priority": "HAUTE"
            },
            8: {
                "name": "[TOOLS] dhatu-evolution-simulator",
                "status": "PLANIFI√â",
                "category": "TOOLS",
                "priority": "BASSE"
            },
            7: {
                "name": "[TOOLS] dhatu-space-visualizer",
                "status": "PLANIFI√â",
                "category": "TOOLS",
                "priority": "BASSE"
            },
            6: {
                "name": "[TOOLS] dhatu-creative-generator",
                "status": "PLANIFI√â",
                "category": "TOOLS",
                "priority": "BASSE"
            },
            5: {
                "name": "[TOOLS] dhatu-pattern-analyzer",
                "status": "PLANIFI√â",
                "category": "TOOLS",
                "priority": "MOYENNE"
            },
            4: {
                "name": "[CORE] dhatu-gpu-accelerator",
                "status": "ACTIF",
                "category": "CORE",
                "priority": "HAUTE"
            },
            3: {
                "name": "[CORE] dhatu-web-framework",
                "status": "PLANIFI√â",
                "category": "CORE",
                "priority": "MOYENNE"
            },
            2: {
                "name": "[CORE] dhatu-corpus-manager",
                "status": "ACTIF",
                "category": "CORE",
                "priority": "HAUTE"
            },
            1: {
                "name": "[CORE] dhatu-universal-compressor",
                "status": "ACTIF",
                "category": "CORE",
                "priority": "CRITIQUE"
            }
        }
    
    def _load_orchestrator_tasks(self) -> Dict[str, Dict[str, Any]]:
        """Charge t√¢ches orchestrateur."""
        # Parse panini_ecosystem_state_*.json le plus r√©cent
        state_files = list(self.workspace_root.glob('panini_ecosystem_state_*.json'))
        
        if not state_files:
            return {}
        
        latest_state = max(state_files, key=lambda p: p.stat().st_mtime)
        
        with open(latest_state, 'r', encoding='utf-8') as f:
            state = json.load(f)
        
        return state.get('tasks', {})
    
    def _scan_active_prs(self) -> List[Dict[str, Any]]:
        """Scan PRs actifs depuis documents."""
        prs = []
        
        # Parse SYNTHESE_CLARIFICATIONS_INTEGREES.md
        synthese_path = self.workspace_root / 'SYNTHESE_CLARIFICATIONS_INTEGREES.md'
        if synthese_path.exists():
            with open(synthese_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            # Extract PR info
            pr_matches = re.findall(
                r'PR\s*#(\d+)[^\n]*?\n[^\n]*?(.+?)(?:\n\n|\Z)',
                content,
                re.DOTALL
            )
            
            for pr_num, description in pr_matches:
                prs.append({
                    'number': int(pr_num),
                    'description': description.strip()[:100]
                })
        
        return prs
    
    def analyze_alignment(self) -> Dict[str, Any]:
        """Analyse alignement complet."""
        print("\nüîç ANALYSE ALIGNEMENT MISSIONS PANINI")
        print("=" * 70)
        
        # 1. D√©tection projets obsol√®tes
        self._detect_obsolete_projects()
        
        # 2. Analyse coh√©rence objectifs
        self._analyze_objectives_coherence()
        
        # 3. D√©tection duplications
        self._detect_duplications()
        
        # 4. Gaps strat√©giques
        self._identify_strategic_gaps()
        
        # 5. Conflits priorit√©s
        self._detect_priority_conflicts()
        
        # 6. Score coh√©rence global
        self._compute_coherence_score()
        
        # 7. Recommandations
        self._generate_recommendations()
        
        self.alignment_report['status'] = 'COMPLETED'
        
        return self.alignment_report
    
    def _detect_obsolete_projects(self):
        """D√©tecte projets potentiellement obsol√®tes."""
        print("\nüìä 1. D√©tection Projets Obsol√®tes")
        print("-" * 70)
        
        obsolete_candidates = []
        
        # Crit√®res obsolescence
        for proj_id, proj_info in self.github_projects.items():
            issues = []
            
            # Status PLANIFI√â + Priority BASSE = potentiellement obsol√®te
            if (proj_info['status'] == 'PLANIFI√â' and 
                proj_info['priority'] == 'BASSE'):
                issues.append("Status PLANIFI√â + Priority BASSE")
            
            # Pas de t√¢ches orchestrateur associ√©es
            has_tasks = any(
                f"panini_{proj_id}_" in task_id
                for task_id in self.orchestrator_tasks
            )
            if not has_tasks and proj_info['status'] == 'PLANIFI√â':
                issues.append("Aucune t√¢che orchestrateur")
            
            # Pas mentionn√© dans docs strat√©giques r√©cents
            mentioned = any(
                str(proj_id) in doc['projects_mentioned']
                for doc in self.strategic_docs.values()
            )
            if not mentioned and proj_info['status'] == 'PLANIFI√â':
                issues.append("Non mentionn√© docs strat√©giques")
            
            if issues:
                obsolete_candidates.append({
                    'project_id': proj_id,
                    'name': proj_info['name'],
                    'issues': issues,
                    'severity': 'HIGH' if len(issues) >= 2 else 'MEDIUM'
                })
        
        if obsolete_candidates:
            self.alignment_report['issues'].append({
                'type': 'OBSOLETE_PROJECTS',
                'count': len(obsolete_candidates),
                'details': obsolete_candidates
            })
            
            print(f"‚ö†Ô∏è  {len(obsolete_candidates)} projets potentiellement obsol√®tes:")
            for candidate in obsolete_candidates:
                print(f"  - Project #{candidate['project_id']}: {candidate['name']}")
                for issue in candidate['issues']:
                    print(f"    ‚Ä¢ {issue}")
        else:
            print("‚úÖ Aucun projet obsol√®te d√©tect√©")
    
    def _analyze_objectives_coherence(self):
        """Analyse coh√©rence objectifs entre documents."""
        print("\nüìä 2. Coh√©rence Objectifs")
        print("-" * 70)
        
        # Extraction objectifs de tous les docs
        all_objectives = []
        for doc_name, doc_data in self.strategic_docs.items():
            for obj in doc_data['objectives']:
                all_objectives.append({
                    'source': doc_name,
                    'text': obj,
                    'date': doc_data['dates'][0] if doc_data['dates'] else 'UNKNOWN'
                })
        
        # D√©tection contradictions (keywords oppos√©s)
        contradictions = []
        opposite_pairs = [
            ('100%', 'seuil'),
            ('binaire', 'pourcentage'),
            ('compose/decompose', 'identit√©'),
            ('QUI/QUAND', 'number'),
            ('√©cosyst√®me', 'seulement')
        ]
        
        for obj1 in all_objectives:
            for obj2 in all_objectives:
                if obj1['source'] != obj2['source']:
                    for keyword1, keyword2 in opposite_pairs:
                        if (keyword1.lower() in obj1['text'].lower() and
                            keyword2.lower() in obj2['text'].lower()):
                            contradictions.append({
                                'doc1': obj1['source'],
                                'doc2': obj2['source'],
                                'conflict': f"{keyword1} vs {keyword2}",
                                'severity': 'MEDIUM'
                            })
        
        if contradictions:
            self.alignment_report['issues'].append({
                'type': 'OBJECTIVE_CONTRADICTIONS',
                'count': len(contradictions),
                'details': contradictions[:5]  # Top 5
            })
            print(f"‚ö†Ô∏è  {len(contradictions)} contradictions potentielles d√©tect√©es")
        else:
            print("‚úÖ Objectifs coh√©rents entre documents")
    
    def _detect_duplications(self):
        """D√©tecte duplications efforts."""
        print("\nüìä 3. Duplications Efforts")
        print("-" * 70)
        
        duplications = []
        
        # Analyse t√¢ches similaires
        task_themes = {}
        for task_id, task_data in self.orchestrator_tasks.items():
            # Extract theme (keywords principaux)
            title = task_data.get('title', '').lower()
            
            for keyword in ['validation', 'extraction', 'dashboard', 
                           'corpus', 'training', 'embeddings']:
                if keyword in title:
                    if keyword not in task_themes:
                        task_themes[keyword] = []
                    task_themes[keyword].append(task_id)
        
        # Duplication si 3+ t√¢ches m√™me th√®me
        for theme, task_ids in task_themes.items():
            if len(task_ids) >= 3:
                duplications.append({
                    'theme': theme,
                    'task_count': len(task_ids),
                    'task_ids': task_ids,
                    'severity': 'MEDIUM'
                })
        
        if duplications:
            self.alignment_report['issues'].append({
                'type': 'EFFORT_DUPLICATIONS',
                'count': len(duplications),
                'details': duplications
            })
            print(f"‚ö†Ô∏è  {len(duplications)} potentielles duplications:")
            for dup in duplications:
                print(f"  - Th√®me '{dup['theme']}': {dup['task_count']} t√¢ches")
        else:
            print("‚úÖ Aucune duplication majeure d√©tect√©e")
    
    def _identify_strategic_gaps(self):
        """Identifie gaps strat√©giques."""
        print("\nüìä 4. Gaps Strat√©giques")
        print("-" * 70)
        
        gaps = []
        
        # Projets ACTIF sans t√¢ches
        for proj_id, proj_info in self.github_projects.items():
            if proj_info['status'] == 'ACTIF':
                has_tasks = any(
                    f"panini_{proj_id}_" in task_id
                    for task_id in self.orchestrator_tasks
                )
                if not has_tasks:
                    gaps.append({
                        'type': 'MISSING_TASKS',
                        'project_id': proj_id,
                        'project_name': proj_info['name'],
                        'severity': 'HIGH' if proj_info['priority'] == 'CRITIQUE' else 'MEDIUM'
                    })
        
        # Cat√©gories sous-repr√©sent√©es
        category_tasks = {}
        for task_id in self.orchestrator_tasks:
            if task_id.startswith('panini_'):
                proj_id = int(task_id.split('_')[1])
                category = self.github_projects[proj_id]['category']
                category_tasks[category] = category_tasks.get(category, 0) + 1
        
        # CORE devrait avoir le plus de t√¢ches
        if category_tasks.get('CORE', 0) < category_tasks.get('TOOLS', 0):
            gaps.append({
                'type': 'CATEGORY_IMBALANCE',
                'issue': 'TOOLS > CORE tasks (invers√©)',
                'severity': 'HIGH'
            })
        
        if gaps:
            self.alignment_report['issues'].append({
                'type': 'STRATEGIC_GAPS',
                'count': len(gaps),
                'details': gaps
            })
            print(f"‚ö†Ô∏è  {len(gaps)} gaps strat√©giques identifi√©s")
        else:
            print("‚úÖ Couverture strat√©gique compl√®te")
    
    def _detect_priority_conflicts(self):
        """D√©tecte conflits priorit√©s."""
        print("\nüìä 5. Conflits Priorit√©s")
        print("-" * 70)
        
        conflicts = []
        
        # Projets CRITIQUE sans t√¢ches high priority
        for proj_id, proj_info in self.github_projects.items():
            if proj_info['priority'] == 'CRITIQUE':
                high_priority_tasks = [
                    task_id for task_id, task_data in self.orchestrator_tasks.items()
                    if f"panini_{proj_id}_" in task_id and
                    task_data.get('priority', 0) >= 8
                ]
                if not high_priority_tasks:
                    conflicts.append({
                        'type': 'PRIORITY_MISMATCH',
                        'project_id': proj_id,
                        'project_name': proj_info['name'],
                        'issue': 'Project CRITIQUE mais aucune t√¢che priority ‚â•8',
                        'severity': 'HIGH'
                    })
        
        if conflicts:
            self.alignment_report['issues'].append({
                'type': 'PRIORITY_CONFLICTS',
                'count': len(conflicts),
                'details': conflicts
            })
            print(f"‚ö†Ô∏è  {len(conflicts)} conflits priorit√©s")
        else:
            print("‚úÖ Priorit√©s coh√©rentes")
    
    def _compute_coherence_score(self):
        """Calcule score coh√©rence global."""
        print("\nüìä 6. Score Coh√©rence Global")
        print("-" * 70)
        
        # Score bas√© sur issues d√©tect√©es
        total_issues = len(self.alignment_report['issues'])
        
        # Pond√©ration par severity
        severity_weights = {'HIGH': 3, 'MEDIUM': 2, 'LOW': 1}
        weighted_issues = 0
        
        for issue_group in self.alignment_report['issues']:
            for detail in issue_group.get('details', []):
                severity = detail.get('severity', 'MEDIUM')
                weighted_issues += severity_weights[severity]
        
        # Score sur 100 (100 = parfait, 0 = chaos)
        max_expected_issues = 20  # Projection
        score = max(0, 100 - (weighted_issues / max_expected_issues) * 100)
        
        self.alignment_report['coherence_score'] = score
        
        if score >= 90:
            status = "EXCELLENT ‚úÖ"
        elif score >= 75:
            status = "BON ‚úÖ"
        elif score >= 60:
            status = "ACCEPTABLE ‚ö†Ô∏è"
        else:
            status = "BESOIN REFACTORING ‚ùå"
        
        print(f"Score: {score:.1f}/100 - {status}")
        print(f"Issues totales: {total_issues}")
        print(f"Issues pond√©r√©es: {weighted_issues}")
    
    def _generate_recommendations(self):
        """G√©n√®re recommandations."""
        print("\nüìä 7. Recommandations")
        print("-" * 70)
        
        recommendations = []
        
        # Bas√© sur issues d√©tect√©es
        for issue_group in self.alignment_report['issues']:
            issue_type = issue_group['type']
            
            if issue_type == 'OBSOLETE_PROJECTS':
                recommendations.append({
                    'priority': 'HIGH',
                    'action': 'ARCHIVE_PROJECTS',
                    'description': f"Archiver {issue_group['count']} projets obsol√®tes",
                    'projects': [d['project_id'] for d in issue_group['details']]
                })
            
            elif issue_type == 'STRATEGIC_GAPS':
                recommendations.append({
                    'priority': 'HIGH',
                    'action': 'ADD_TASKS',
                    'description': f"Cr√©er t√¢ches pour {issue_group['count']} gaps",
                    'details': issue_group['details']
                })
            
            elif issue_type == 'PRIORITY_CONFLICTS':
                recommendations.append({
                    'priority': 'HIGH',
                    'action': 'ADJUST_PRIORITIES',
                    'description': f"Corriger {issue_group['count']} conflits priorit√©s"
                })
            
            elif issue_type == 'EFFORT_DUPLICATIONS':
                recommendations.append({
                    'priority': 'MEDIUM',
                    'action': 'CONSOLIDATE_TASKS',
                    'description': f"Consolider {issue_group['count']} duplications"
                })
        
        # Recommandations g√©n√©rales
        if self.alignment_report['coherence_score'] < 75:
            recommendations.append({
                'priority': 'CRITICAL',
                'action': 'STRATEGIC_REVIEW',
                'description': 'Session review strat√©gique compl√®te recommand√©e'
            })
        
        self.alignment_report['recommendations'] = recommendations
        
        if recommendations:
            print(f"\nüí° {len(recommendations)} recommandations:")
            for rec in recommendations:
                print(f"  [{rec['priority']}] {rec['action']}: {rec['description']}")
        else:
            print("‚úÖ Aucune action requise - alignement optimal")
    
    def export_report(self, output_file: Optional[Path] = None) -> Path:
        """Export rapport alignement."""
        if output_file is None:
            timestamp = datetime.now(timezone.utc).strftime('%Y-%m-%dT%H-%M-%SZ')
            output_file = (
                self.workspace_root /
                f'mission_alignment_report_{timestamp}.json'
            )
        
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.alignment_report, f, indent=2, ensure_ascii=False)
        
        print(f"\n‚úÖ Rapport export√©: {output_file.name}")
        return output_file


def main():
    """Point d'entr√©e principal."""
    workspace = "/home/stephane/GitHub/PaniniFS-Research"
    
    analyzer = MissionAlignmentAnalyzer(workspace)
    
    # Analyse compl√®te
    report = analyzer.analyze_alignment()
    
    # Export
    output = analyzer.export_report()
    
    # R√©sum√© final
    print("\n" + "=" * 70)
    print(f"üìä R√âSUM√â ANALYSE ALIGNEMENT")
    print("=" * 70)
    print(f"Score coh√©rence: {report['coherence_score']:.1f}/100")
    print(f"Issues d√©tect√©es: {len(report['issues'])}")
    print(f"Recommandations: {len(report['recommendations'])}")
    
    if report['coherence_score'] >= 75:
        print(f"\n‚úÖ Alignement satisfaisant - Pr√™t √† activer ressources")
    else:
        print(f"\n‚ö†Ô∏è  Alignement insuffisant - Review recommand√©e avant activation")


if __name__ == '__main__':
    main()
